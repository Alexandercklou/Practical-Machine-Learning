0.64
mypdf
mypdf(0.8,1.6)
mypdf(0.8)
integrate(mypdf,0,1.6)
x^2/2
2
1
0.4
2
x^2/2
x^2/2
1.4
integrate(mypdf,0,1.6)
info()
1
2
3
4
1
0
0.2
integrate(mypdf,0,1.6)
integrate(mypdf,0,1.6)
integrate(mypdf,0,1.6)
2
1.5
1
4
x
2
1.5
info()
0.5
x
median(x)
0
1
2
1
12
3
4
5
3
x^2
x^2*.5
3
4
5
6
7
1
0.5
sqrt(2)
0.997*0.01
0.997*0.001
0.997*0.001*0.985
0.001*0.985
0.001*0.015
0.985*0.003
0.985*0.001
0.003*0.999
0.003*0.99
0.03*0.99
0.003/0.997*0.001/0,999
0.003/0.997*0.001/0.999
0.997/0.003*0.001/0.999
info()
skip()
skip()
23
23
23
4
5
6
7
89
1
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
head(adData)
head(diagnosis)
head(diagnosis)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(mixtures)
hist(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
names(training)
subsetNames<-training[,grep("IL",colnames(training))]
names(subsetNames)
T<-subsetNames[,-14]
names(T)
T<-subsetNames[,-13]
names(T)
preProcValues <- preProcess(T, method = c("center", "scale"))
head(preProcValues)
preProcValues <- preProcess(T, method = "pca")
head(preProcValues)
preProcValues
M<-abs(cor(T))
M
diag(M)<-0
which(M>0.8,arr,ind=T)
which(M>0.8,arr.ind=T)
which(M>0.8,arr.ind=T)
M
which(M > 0.8 , arr.ind=T )
M>0.8
preProcValues <- preProcess(log10(T+1), method = "pca")
names(training)
preProcValues <- preProcess(T, method = "pca",thresh=0.9)
preProcValues$rotation
preProcValues$numComp
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subsetNames<-training[,grep("IL"||"diagnosis",colnames(training))]
subsetNames<-training[,grep("IL||diagnosis",colnames(training))]
subsetNames<-training[,grep("IL||diagnosis",colnames(training))]
names(subsetNames)
subsetNames<-training[,grep("IL|diagnosis",colnames(training))]
names(subsetNames)
subsetNames<-subsetNames[,-14]
modelFit1<-train(subsetNames$diagnosis~,method="glm",data=subsetNames)
modelFit1<-train(subsetNames$diagnosis~.,method="glm",data=subsetNames)
modelFit2<-train(subsetNames$diagnosis~.,method="glm",preProcess="pca",thresh=0.8,data=subsetNames)
modelFit2<-train(subsetNames$diagnosis~.,method="glm",preProcess="pca",thresh=0.8,data=subsetNames, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
modelFit2<-train(subsetNames$diagnosis~.,method="glm",preProcess="pca",data=subsetNames, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
confusionMatrix(testing$diagnosis, predict(modelFit1, testing))
confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='alexanderlou',
token='8C8B5F7D8A91696B836967B9F27402CD',
secret='<SECRET>')
shinyapps::setAccountInfo(name='alexanderlou',token='8C8B5F7D8A91696B836967B9F27402CD',secret='<SECRET>')
shinyapps::setAccountInfo(name='alexanderlou',
token='8C8B5F7D8A91696B836967B9F27402CD',
secret='YLHPIaAF8BnZx3OLqd9mGCwhcel4aG5jabvNELZk')
library(shinyapps)
shinyapps::deployApp('path/to/your/app')
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages("rCharts")
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
str(segmentationOriginal)
training<-segmentationOriginal[Case=="Train",]
testing<-segmentationOriginal[Case=="Test",]
ModelFit<-train(diagnosis~.,data=T,method="rpart")
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
ModelFit<-train(Class~.,data=training,method="rpart")
plot(ModelFit$finalModel,uniform=TRUE)
text(ModelFit$finalModel,use.n = TRUE,cex=.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
ModelFit2<-train(Area~.,data=olive,method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
K<-predict(ModelFit2,newdata)
K
head(Olive)
head(olive)
str(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
ModelFit3<-train(chd~.,data=trainSA,method="glm")
ModelFit3<-glm(chd~.,family = binomial (logit),data=trainSA)
T<-predict(ModelFit,testSA)
T<-predict(ModelFit3,testSA)
T
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(chd,T)
missClass(testSA$chd,T)
missClass(testSA$chd,T$chd)
missClass(testSA$chd,ModelFit3)
missClass(testSA$chd,ModelFit3$chd)
missClass(testSA$chd,ModelFit3)
missClass(testSA$chd,ModelFit3$chd)
missClass(testSA$chd,T)
missClass(trainSA$chd,T)
ModelFit3<-glm(chd~.,family = binomial,data=trainSA)
T<-predict(ModelFit3,testSA)
missClass(trainSA$chd,T)
missClass(testSA$chd,T)
T<-predict(ModelFit3,trainSA)
missClass(trainSA$chd,T)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model <- train(y ~ ., data = vowel.train,method="rf")
order(varImp(model), decreasing=T)
varImp(model)
order(varImp(model))
T<-performance(ModelFit3,measure="tpr",x.measure="fpr")
T<-performance(ModelFit3,measure="tpr",x.measure="fpr")
install.packages("RORC")
install.packages("ROCR")
library(ROCR)
T<-performance(ModelFit3,measure="tpr",x.measure="fpr")
T<-performance(T,measure="tpr",x.measure="fpr")
pred <- prediction(T, labels)
pred <- prediction(ModelFit3, labels)
pred <- prediction(ModelFit3, trainSA)
pred <- prediction(ModelFit2, newdata)
plot(performance(prediction(ModelFit2, olive$Area), 'tpr', 'fpr'))
plot(performance(prediction(ModelFit2$pred, olive$Area), 'tpr', 'fpr'))
rocplot(ModelFit3)
install.packages("rocplot")
library(rocplot)
install.packages("rocplot")
install.packages("pROC")
library(pROC)
install.packages("ROSE")
library(ROSE)
roc.curve(trainSA$chd,T,main="ROC curve \n (Half circle depleted data)")
set.seed(1234567890)
install.packages("neuralnet")
library("neuralnet")
dataset <- read.csv("creditset.csv")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
RFT<-train(y~.,data=vowel.train,method='rf')
library(caret)
RFT<-train(y~.,data=vowel.train,method='rf')
Boost<-train(y~.,data=vowel.train,method='gbm')
pred1<-predict(RFT,vowel.test)
pred2<-predict(Boost,vowel.test)
pred1$finalModel
pred1
RFT$finalModel
confusionMatrix(pred1,vowel.train$y)
confusionMatrix(pred1$y,vowel.train$y)
confusionMatrix(pred1,vowel.train)
confusionMatrix(pred1,vowel.train$y)
confusionMatrix(predict(RFT,vowel.test),vowel.test$y)
confusionMatrix(predict(Boost,vowel.test),vowel.test$y)
predDF<-data.frame(pred1,pred2,y=vowel.test$y)
commodfit<-train(y~.,method="gam",data=predDF)
mmodfit<-train(y~.,method="gam",data=predDF)
combPred<-predict(commodfit,predDF)
commodfit<-train(y~.,method="gam",data=predDF)
combPred<-predict(commodfit,predDF)
combPred
confusionMatrix(predict(commodfit,predDF),vowel.test$y)
confusionMatrix(predict(commodfit,predDF),predDF$y)
commodfit<-train(y~.,method="gam",data=predDF)
combPred<-predict(commodfit,predDF)
confusionMatrix(predict(commodfit,predDF),predDF$y)
confusionMatrix(predict(commodfit,predDF),test$y)
confusionMatrix(predict(commodfit,predDF),vowel.test$y)
predDF<-data.frame(pred1,pred2,y=vowel.test$y, agree=pred1 == pred2)
commodfit<-train(y~.,method="gam",data=predDF)
combPred<-predict(commodfit,predDF)
confusionMatrix(predict(commodfit,predDF),vowel.test$y)
accuracy <- sum(pred1[predDF<$agree] == predDF$y[predDF<$agree]) / sum(predDF<$agree)
accuracy <- sum(pred1[predDF<$agree]== predDF$y[predDF$agree]) / sum(predDF$agree)
accuracy <- sum(pred1[predDF$agree]== predDF$y[predDF$agree]) / sum(predDF$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
M1<-train(diagnosis~.,data=training,method='rf')
M2<-train(diagnosis~.,data=training,method='gbm')
M3<-train(diagnosis~.,data=training,method='lda')
Pm1<-predict(M1,testing)
Pm2<-predict(M2,testing)
Pm3<-predict(M3,testing)
predDF<-data.frame(Pm1,Pm2,Pm3,diagnosis=testing$diagnosis)
commodfit<-train(diagnosis~.,method="rf",data=predDF)
combPred<-predict(commodfit,predDF)
confusionMatrix(predict(commodfit,predDF),testing$diagnosis)
confusionMatrix(Pm1,testing$diagnosis)
confusionMatrix(Pm1,testing$diagnosis)$Accuracy
confusionMatrix(Pm1,testing$diagnosis)[1]
confusionMatrix(Pm1,testing$diagnosis)[2]
confusionMatrix(Pm1,testing$diagnosis)[3]
confusionMatrix(Pm1,testing$diagnosis)[4]
str(confusionMatrix)
names(confusionMatrix())
names(confusionMatrix)
confusionMatrix(Pm1,testing$diagnosis)[3]
confusionMatrix(Pm1,testing$diagnosis)[3]
confusionMatrix(Pm2,testing$diagnosis)[3]
confusionMatrix(Pm3,testing$diagnosis)[3]
confusionMatrix(Pm1,testing$diagnosis)[3]
confusionMatrix(Pm2,testing$diagnosis)[3]
confusionMatrix(Pm3,testing$diagnosis)[3]
confusionMatrix(predict(commodfit,predDF),testing$diagnosis)[3]
confusionMatrix(Pm1,testing$diagnosis)$overall[1]
confusionMatrix(Pm2,testing$diagnosis)$overall[1]
confusionMatrix(Pm3,testing$diagnosis)$overall[1]
confusionMatrix(predict(commodfit,predDF),testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
head(concrete)
Model<-train(CompressiveStrength~.,data=training,method='lasso')
Model<-train(CompressiveStrength~.,data=training,method='lasso')
?plot.enet
plot.enet(Model$finalModel, xvar="penalty", use.color=T)
if (!file.exists("./gaData.csv")) {
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", destfile="./gaData.csv", method = "libcurl")
}
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
library(forecast)
est1<-bat(tstrain)
tstrain = ts(training$visitsTumblr)
est1<-bats(tstrain)
pred<-forecast(est1,level=95,h=testing$visitsTumblr)
pred<-forecast(est1,level=95,h=dim(testing)[1])
predComb<-cbind(testing,data.frame(pred))
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) & (predComb$visitsTumblr < predComb$Hi.95)
predComb$in95
prop.table(table(predComb$in95))[2]
library(e1071)
Model<-svm(CompressiveStrength~.,data=training)
pred<-predict(Model,testing)
acc<-accuracy(pred,testing$CompressiveStrength)
acc[2]
Model<-svm(CompressiveStrength~.,data=training)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
Model<-svm(CompressiveStrength~.,data=training)
pred<-predict(Model,testing)
acc<-accuracy(pred,testing$CompressiveStrength)
acc[2]
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
Model<-svm(CompressiveStrength~.,data=training)
pred<-predict(Model,testing)
acc<-accuracy(pred,testing$CompressiveStrength)
acc[2]
getwd()
setwd("/Users/alexanderlou/datasciencecoursera/")
setwd("/Users/alexanderlou/datasciencecoursera/Practical Machine Learning")
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
library(pROC)
if (!file.exists("./pml-training.csv"))
{
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="./pml-training.csv", method = "libcurl")
}
if (!file.exists("./pml-testing.csv"))
{
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="./pml-testing.csv", method = "libcurl")
}
Training<-read.csv("./pml-training.csv",header = TRUE, na.strings = c("NA",""),sep=",")
Testing<-read.csv("./pml-testing.csv",header = TRUE, na.strings =  c("NA",""),sep=",")
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
library(pROC)
nzv <- nearZeroVar(Training, saveMetrics=TRUE)
Training <- Training[,nzv$nzv==FALSE]
nzv1<- nearZeroVar(Testing,saveMetrics=TRUE)
Testing <- Testing[,nzv1$nzv==FALSE]
Training<-Training[,-1]
Testing<-Testing[,-1]
classe1<-Training$classe
classe2<-Testing$classe
Training <- Training[, sapply(Training, is.numeric)]
Testing <- Testing[, sapply(Testing, is.numeric)]
Training$classe<-classe1
Training<-Training[,colSums(is.na(Training))==0]
Testing<-Testing[,colSums(is.na(Testing))==0]
dim(Training)
traincontrol <- trainControl(method = "cv", number = 10,classProbs = TRUE)
```
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
library(pROC)
if (!file.exists("./pml-training.csv"))
{
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="./pml-training.csv", method = "libcurl")
}
if (!file.exists("./pml-testing.csv"))
{
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="./pml-testing.csv", method = "libcurl")
}
Training<-read.csv("./pml-training.csv",header = TRUE, na.strings = c("NA",""),sep=",")
Testing<-read.csv("./pml-testing.csv",header = TRUE, na.strings =  c("NA",""),sep=",")
Training<-Training[,colSums(is.na(Training))==0]
Testing<-Testing[,colSums(is.na(Testing))==0]
nzv <- nearZeroVar(Training, saveMetrics=TRUE)
Training <- Training[,nzv$nzv==FALSE]
nzv1<- nearZeroVar(Testing,saveMetrics=TRUE)
Testing <- Testing[,nzv1$nzv==FALSE]
Training<-Training[,-1]
Testing<-Testing[,-1]
classe1<-Training$classe
classe2<-Testing$classe
Training <- Training[, sapply(Training, is.numeric)]
Testing <- Testing[, sapply(Testing, is.numeric)]
Training$classe<-classe1
set.seed(820910)
inTrain<-createDataPartition(y=Training$classe,p=0.6,list=FALSE)
Train1<-Training[inTrain,]
Train2<-Training[-inTrain,]
traincontrol <- trainControl(method = "cv", number = 10,classProbs = TRUE)
RegModel<-train(classe~.,method = "multinom", data=Train1,trControl=traincontrol)
Model1<-predict(RegModel,newdata=Train2)
confusionMatrix(Model1,Train2$classe)
DecisionTree<-rpart(classe~.,method ="class", data=Train1)
Model2<-predict(DecisionTree,newdata=Train2,type="class")
confusionMatrix(Model2,Train2$classe)
DecisionTree<-rpart(classe~.,method ="class", data=Train1)
Model2<-predict(DecisionTree,newdata=Train2,type="class")
confusionMatrix(Model2,Train2$classe)
confusionMatrix(Model1,Train2$classe)
confusionMatrix(Model1,Train2$classe)
confusionMatrix(Model2,Train2$classe)
confusionMatrix(Model2,Train2$classe)
We start the Multi-nomial Regression first
DecisionTree<-rpart(classe~.,method ="class", data=Train1)
Model2<-predict(DecisionTree,newdata=Train2,type="class")
confusionMatrix(Model2,Train2$classe)
```{r plot2, fig.align='center',fig.height=4,echo=FALSE,cache=TRUE,results='hide'}
